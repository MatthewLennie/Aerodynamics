{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series classification of Aerodynamics\n",
    "The boundary layer on an airfoil can be in two states, Laminar or Turbulent. Visually this switch is quite easy to see, for the aerodynamics muggles, the turbulent boundary layer state with show up on the time series data from the microphone as very turbulent(or volatile if you are from the finance world). \n",
    "Other ways to solve this problem include\n",
    "- Traditional signal processing tricks that can extract such a change over of course. \n",
    "- Bayesian switch point analysis with a flexible number of switch points would also work. \n",
    "- The auto-regressive type models<br>\n",
    "But I wanted to try my hand at getting a time series model in torch working, so here we are. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principles learnt:\n",
    "- Training data has to be very good!! Fix this before trying fancy stuff like ensembling etc... \n",
    "- write test train data loading as a loop less code = less bugs. \n",
    "- Display metrics for all batches in validation set. single batches don't converge enough to give good results. Not a corner worth cutting\n",
    "- Keep training even when the accuracy metric flattens out. Much of the struggle I had was simply not training long enough, the accurancy had flattened out but the pre-thresholded values contintued to go further to the rails. This meant that on the test set that the nn was more robust. Overfitting was still not a problem as nn used here was a little bit underpowered to start with so early stopping was not really nessescary. Training for 500-600 Epochs was in the end what produced the best model. A special regularization for output smoothness didn't seem nessescary in this case. \n",
    "- plot_grad_flow can help understand the architecture decisions i.e exploding or vanishing gradients. \n",
    "- Even though I didn't use an ensemble, I learnt that you can make snapshot ensembles or perform and ensemble fo the weights them selves and thus just keep one model. You can also ensemble across model types. i.e. CNN + RNN. Didn't end up need this although the architecture was almost built here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.vision.transform import *\n",
    "import posixpath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Model\n",
    "Multple Layer LSTM to fully conencted.\n",
    "Sigmoid on the out layer as it is a binary classification problem. \n",
    "11> Lstm became difficult to train and didn't have the time to implement LR slicing across layers\n",
    "The resulting model tends to be slightly biased and therefore quite resistant to overfitting. There isn't huge amounts of good training data so it will do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,\n",
    "                    num_layers=2):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
    "\n",
    "        # Define the output layer\n",
    "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
    "        \n",
    "        self.Sig = nn.Sigmoid()\n",
    "        \n",
    "    def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, input):\n",
    "        \n",
    "        # Forward pass through LSTM layer\n",
    "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
    "        # shape of self.hidden: (a, b), where a and b both \n",
    "        # have shape (num_layers, batch_size, hidden_dim).\n",
    "        \n",
    "        #input.view(self.input_dim, self.batch_size, -1)\n",
    "        lstm_out, self.hidden = self.lstm(input.view(-1,len(input),8))\n",
    "        \n",
    "        # Only take the output from the final timetep\n",
    "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
    "        y_pred = self.Sig(self.linear(lstm_out[-1].view(len(input), -1)))\n",
    "        return y_pred.view(-1)\n",
    "\n",
    "#model = LSTM(lstm_input_size, h1, batch_size=num_train, output_dim=output_dim, num_layers=num_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data\n",
    "The features of the time series have been pre-processed to include the time series itself and the first 6 mel-spectrum coefficients for more information see Librosa MFCC. Note that I did not split the test train sets before processing these coefficients which may constitute peeking, However, I finally tested the algorithm on files that were completely independent, the model seems to generalize well. I believe that one the batch size we are talking about the statistics have converged to the population values so we won't face any problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadData(): #just doing it as a function to clean up whats in scope/ \n",
    "    #training files deliberately chosen to have a good representation of the classes and tend to be towards the leading edge\n",
    "    # Trailing edge microphones naturally tend to be turbulent the whole time. \n",
    "    df = pd.read_pickle(\"./NewSensorData/Sensor10\")\n",
    "    Split = 0.8\n",
    "    SplitInd = int(Split * len(df))\n",
    "    LabelList = ['ts',*range(7)]\n",
    "    Input = torch.tensor(df[LabelList].values)\n",
    "    Output = torch.tensor(df['Labels'].values)\n",
    "\n",
    "    #load second file hacky way for now. Only two files needed for training set.  \n",
    "    df3 = pd.read_pickle(\"./NewSensorData/Sensor11\")\n",
    "\n",
    "    Input3 = torch.tensor(df3[LabelList].values)\n",
    "    Output3 = torch.tensor(df3['Labels'].values)\n",
    "\n",
    "    df4 = pd.read_pickle(\"./NewSensorData/Sensor0\")\n",
    "    \n",
    "    Input4 = torch.tensor(df4[LabelList].values)\n",
    "    Output4 = torch.tensor(df4['Labels'].values)\n",
    "\n",
    "    #Valid trainSplit\n",
    "    InpTrain4, InpValid4 = Input4[:SplitInd], Input4[SplitInd:]\n",
    "    OutTrain4, OutValid4 = Output4[:SplitInd], Output4[SplitInd:]\n",
    "\n",
    "\n",
    "    #Valid trainSplit\n",
    "    InpTrain, InpValid = Input[:SplitInd], Input[SplitInd:]\n",
    "    OutTrain, OutValid = Output[:SplitInd], Output[SplitInd:]\n",
    "\n",
    "    #Valid trainSplit\n",
    "    InpTrain3, InpValid3 = Input3[:SplitInd], Input3[SplitInd:]\n",
    "    OutTrain3, OutValid3 = Output3[:SplitInd], Output3[SplitInd:]\n",
    "\n",
    "    #Concat two files. \n",
    "    InputTrain = torch.cat((InpTrain,InpTrain3,InpTrain4),0)\n",
    "    InputValid = torch.cat((InpValid,InpValid3,InpValid4),0)\n",
    "    OutputTrain = torch.cat((OutTrain,OutTrain3,OutTrain4),0)\n",
    "    OutputValid = torch.cat((OutValid,OutValid3,OutValid4),0)\n",
    "\n",
    "    #Train scaler on training data only. No peeking now!! \n",
    "    InpScaler = StandardScaler()\n",
    "    InpScaler.fit(InputTrain)\n",
    "\n",
    "    InputTrain = torch.tensor(InpScaler.transform(InputTrain))\n",
    "    InputValid = torch.tensor(InpScaler.transform(InputValid))\n",
    "\n",
    "    BatchSize = 200000\n",
    "    #Into DataLoaders\n",
    "    # Large Batch size seems to perform better. \n",
    "    TrainDataSet = torch.utils.data.TensorDataset(InputTrain, OutputTrain)\n",
    "    Train = torch.utils.data.DataLoader(TrainDataSet,batch_size = BatchSize,num_workers = 1)\n",
    "\n",
    "    ValidDataSet = torch.utils.data.TensorDataset(InputValid, OutputValid)\n",
    "    Valid = torch.utils.data.DataLoader(TrainDataSet,batch_size = BatchSize,num_workers = 1)\n",
    "    LenTrain = len(InpTrain)\n",
    "    LenValid = len(InpValid)\n",
    "    return Train, Valid, BatchSize, InpScaler, LabelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Valid, BatchSize,InpScaler,LabelList = LoadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save out scaler for use in other notebooks. \n",
    "with open('scaler.pickle', 'wb') as file:\n",
    "    pickle.dump(InpScaler,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate with Simple paralell architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Classifier(8, 8, batch_size=BatchSize, output_dim=1, num_layers=11)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam optimizer with Cosine Annealing\n",
    "Achieved 92% without momentum, Cosine Annealing appears effective from training. \n",
    "Have to implement a LR finder to better set. Works for now, probably could achieve much faster training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.2e-2\n",
    "#optimizer = torch.optim.ASGD(model.parameters(),lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,10,0.1*lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training Loop \n",
    "%matplotlib inline\n",
    "highest = 0\n",
    "regular = 0\n",
    "for k in range(400):\n",
    "    \n",
    "    running_loss= 0 \n",
    "    corrects = 0\n",
    "    #Train\n",
    "    for inp, target in Train:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        inp = inp.cuda()\n",
    "        output = model.forward(inp.float())\n",
    "        #train\n",
    "        Thresholded = torch.gt(output.float(),torch.tensor([0.5]).float().cuda()).float()\n",
    "        loss = nn.functional.binary_cross_entropy(output, target.float().cuda()) #+ regular*torch.nn.functional.mse_loss(Conv(Thresholded.reshape([1,1,output.shape[0]])),torch.zeros([1,1,output.shape[0]-1]).cuda()) \n",
    "        #loss = CrossEntropy(output, target.float().reshape(output.shape).cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss/len(target)  \n",
    "            \n",
    "    if k % 1==0: \n",
    "        print(\"epoch{}\".format(k))\n",
    "        print(\"train loss: {}\".format(running_loss))\n",
    "        #print(\"regular: {}\".format(regular*torch.nn.functional.mse_loss(Conv(output.reshape([1,1,output.shape[0]])),torch.zeros([1,1,output.shape[0]-1]).cuda())/len(target)))\n",
    "    running_loss= 0 \n",
    "    # Added the option of just running the Training step for the first few epochs.\n",
    "    if k > -1:\n",
    "        # Validate. \n",
    "        a = np.array([])\n",
    "        b= np.array([])\n",
    "        for inp, target in Valid:\n",
    "            inp = inp.cuda()\n",
    "            output = model.forward(inp.float())\n",
    "            Thresholded = torch.gt(output,torch.tensor([0.5]).float().cuda()).float()\n",
    "            #valid\n",
    "            loss = nn.functional.binary_cross_entropy(output, target.float().reshape(output.shape).cuda()) #+ regular*torch.nn.functional.mse_loss(Conv(Thresholded.reshape([1,1,output.shape[0]])),torch.zeros([1,1,output.shape[0]-1]).cuda())\n",
    "            #Track Epoch Loss\n",
    "            running_loss += loss/len(target)\n",
    "            a = np.append(a,(output>0.5).cpu().numpy()) \n",
    "            b = np.append(b,(target.reshape(output.shape)>0.5).numpy())\n",
    "        \n",
    "        #Print out. \n",
    "        if k % 1 ==0: \n",
    "            print(\"valid loss: {}\".format(running_loss))\n",
    "            print(\"accuracy: {} %\".format((a==b).mean().item()*100))\n",
    "            if ((a==b).mean().item()*100)> highest:\n",
    "                highest = ((a==b).mean().item()*100)\n",
    "                #Save out model that achieves best accuracy. \n",
    "                torch.save(model.state_dict(), './ModelSave3.pt')\n",
    "                print(\"saved\")\n",
    "            plt.figure()    \n",
    "            sns.heatmap(confusion_matrix(a,b))\n",
    "            plt.show()\n",
    "        if k % 20 ==0:\n",
    "            torch.save(model.state_dict(), './ModelSave{}.pt'.format(k))\n",
    "            \n",
    "    print(\"Learning Rate:{}\".format(scheduler.get_lr()))\n",
    "    scheduler.step() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For evaluating nn architecture \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "# This code was copied from a blog. \n",
    "def plot_grad_flow(named_parameters):\n",
    "    '''Plots the gradients flowing through different layers in the net during training.\n",
    "    Can be used for checking for possible gradient vanishing / exploding problems.\n",
    "    \n",
    "    Usage: Plug this function in Trainer class after loss.backwards() as \n",
    "    \"plot_grad_flow(self.model.named_parameters())\" to visualize the gradient flow'''\n",
    "    ave_grads = []\n",
    "    max_grads= []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "            max_grads.append(p.grad.abs().max())\n",
    "    plt.bar(np.arange(len(max_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(max_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom = -0.001, top=0.02) # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "plot_grad_flow(model.named_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model\n",
    "Run the RNN model over the results on a new file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define bandswitching function that switches essentially only when it hits rails. Makes each state sticky. Was less important in well trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandSwitch(window):\n",
    "    if window[-1]>0.7:\n",
    "        return 1\n",
    "    elif window[-1]<0.3:\n",
    "        return 0\n",
    "    else: \n",
    "        return float('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Classifier(8, 8, batch_size=BatchSize, output_dim=1, num_layers=11)\n",
    "model2.load_state_dict(torch.load('./ModelSave3.pt'))\n",
    "model2.cuda()\n",
    "for k in range(47):\n",
    "    # Get new data. \n",
    "    df = pd.read_pickle(\"./NewSensorData/Sensor{}\".format(k))\n",
    "\n",
    "    #Load into Torch Dataset. \n",
    "    Input = torch.tensor(InpScaler.transform(df[['ts',0,1,2,3,4,5,6]].values))\n",
    "    Output = torch.tensor(df['Labels'].values)\n",
    "    #Data -> Torch objects\n",
    "    MainDataSet = torch.utils.data.TensorDataset(Input, Output)\n",
    "    Main = torch.utils.data.DataLoader(MainDataSet,batch_size = 200000,num_workers = 1)\n",
    "    full_results = torch.Tensor()\n",
    "    #Run Model over the batches. \n",
    "    for inp, Label in Main:\n",
    "        inp = inp.cuda()\n",
    "        #maybe faster to turn off grads in future. Performance not a concern here. \n",
    "        output = model2.forward(inp.float())\n",
    "\n",
    "        full_results = torch.cat((full_results,output.cpu()),0)\n",
    "    df['rnnLabs'] = full_results.cpu().detach().numpy()\n",
    "    #create Filtered Labels\n",
    "    df['rnnFiltered'] = df['rnnLabs'].rolling(2).mean().rolling(2).apply(bandSwitch,raw=True).fillna(method='ffill').fillna(method='bfill')\n",
    "    df['LabelsFiltered'] = df['Labels'].rolling(2).mean().rolling(2).apply(bandSwitch,raw=True).fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "    df.to_pickle(\"./Processed/Sensor{}\".format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "df[['ts','Labels','rnnLabs','rnnFiltered']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN ---- Still using the not very well implemented input data. \n",
    "For Demonstration purposes. This code does not perform well. !!!\n",
    "Input data still Melspectrum reduced with POD. Will probably perform as well as RNN with better input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create picture of spectrum for a single df group \n",
    "# Save the file name with a random name and store the relationship in df\n",
    "def pictureFromWindow(g):\n",
    "    #print(g)\n",
    "    ind = g[1].index[3]\n",
    "    Lab = np.random.randint(0,1e15)\n",
    "    #print(df.loc[g][['ts',0,1,2,3,4,5]])\n",
    "    im = Image.fromarray(np.uint8((g[1][['ts',0,1,2,3,4,5]].values+1)*125))\n",
    "    #print(\"./Pictures/{}/{}/{}.jpeg\".format(case,Lab,next(p)))\n",
    "    im.save(\"./Pictures/{}/{}.jpeg\".format(\"test\",Lab))\n",
    "    return Lab,ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop over time each 7 time steps being a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#p = iter(range(1000000000))\n",
    "grouped = df.groupby(np.arange(len(df.index))//7)\n",
    "df['Pictures'] = np.nan\n",
    "for group in grouped:\n",
    "    if group[1].shape[0]==7:\n",
    "        Lab, ind = pictureFromWindow(group)\n",
    "        df.loc[ind,'Pictures'] = int(Lab)\n",
    "#df['Pictures'] = df['Pictures'].astype('int').interpolate(method='nearest')\n",
    "#df['Pictures'] = df['Pictures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "short = df.dropna()\n",
    "short['PicturePath'] = short['Pictures'].apply(lambda x : \"/test/{}.jpeg\".format(int(x)))\n",
    "short.rename(columns ={'LabelsFiltered':'label','PicturePath':'name'})[['name','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = ImageDataBunch.from_df('./Pictures', short , size=7).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NNLabel'] = full_results.detach().numpy()\n",
    "df['Filtered'] = df['NNLabel'].rolling(10).mean().rolling(2).apply(bandSwitch)\n",
    "df= df.fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Time Series\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(20,10))\n",
    "#plt.plot(full_results[:,-1].detach().numpy())\n",
    "#plt.plot(full_results[:,-2].detach().numpy())\n",
    "\n",
    "plt.plot(df['ts'].values[:])\n",
    "plt.plot(df['NNLabel'].values[:],'k')\n",
    "plt.plot(df['Filtered'].values[:],'r')\n",
    "plt.plot(df['Labels'].values[:],'y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.vision.transform import *\n",
    "import posixpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2056\n",
    "data = ImageDataBunch.from_folder(\"./Pictures/\", size=7, bs=bs).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = create_cnn(data, models.resnet50, metrics=error_rate)\n",
    "learn.load('stage-1-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [learn.predict(img)[2][1].numpy().item() for img in learn.data.train_ds.x[:30000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [int(posixpath.basename(posixpath.splitext(item)[0])) for item in data.train_ds.items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPredict = pd.DataFrame({\"real\":data.train_ds.y.items[:30000],\"nnLabel\":predictions[:30000],\"path\":paths[:30000]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPredict.set_index(\"path\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bandSwitch(window):\n",
    "    if window[-1]>0.9:\n",
    "        return 1\n",
    "    elif window[-1]<0.1:\n",
    "        return 0\n",
    "    else: \n",
    "        return float('NaN')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPredict.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPredict['Filtered'] = dfPredict['nnLabel'].rolling(2).mean().rolling(2).apply(bandSwitch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPredict= dfPredict.fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(dfPredict[\"real\"].values,lw=10)\n",
    "plt.plot(dfPredict[\"nnLabel\"].values,color = 'r')\n",
    "plt.plot(dfPredict[\"Filtered\"].values,color = 'k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
